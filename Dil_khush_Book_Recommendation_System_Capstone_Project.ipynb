{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dil150898/Book-Recommendation-System--Capstone-Project/blob/main/Dil_khush_Book_Recommendation_System_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  **Book Recommendation System**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Team\n",
        "##### **Team Member 1 -**Vaibhav Kumar Gupta\n",
        "##### **Team Member 2 -**Bhavik Verma\n",
        "##### **Team Member 3 -**Priyanka Pal\n",
        "##### **Team Member 4 -**Dil Khush Sharma\n",
        "##### **Team Member 5 -**Shayan Somanna"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This project is all about recomendation system.In this project we have tried to use some approches for recomending the books to the readers or users .We have used various ways such as collaborative Filtering and Content based Filtering for recomendation of the books to the users .\n",
        "\n",
        "**ABOUT THE DATASET :** We have three diffrent datsets namely book.csv which contains information about the books such as book-author , publisher , book title , year of publication, image links and unique Book ID i.e ISBN Number .Then we have ratings.csv which contain information about ratings given by the users for the books, it contains user ID ,ISBN number and book rating (scale between 1-10). Then we have users.csv which contain information about users such as their location , age and their user ID \n",
        "\n",
        "**EDA :** For the EDA part we have analysed about the top Books rated by the users , top authors who got most ratings , top authors on the basis of number of books , Top publishers who have published maximum number of books, we have analysed the users age and lastly we have analysed their ratings we got that most of the users have rated 8.\n",
        "\n",
        "**Recomendation Approaches :**\n",
        "\n",
        "*  Collaborative Filtering\n",
        "\n",
        "   In Collaborative Filtering we make predictions of the taste or the intrests of the user based based on the other similar users behaviour (which is called collaborative) .The simple understanding is that if a person P1 have similar opinion with person P2 , then if person P1 is reading Harry Potter books then person P2 may also read Harry Potter books\n",
        "\n",
        "   Collaborative Filtering has mainly two implimentaion strategies\n",
        "   *   Model Based\n",
        "   *   Memory Based\n",
        "\n",
        "We have used the following approaches\n",
        "\n",
        "   Memory based\n",
        "   *  User_based Collaborative Filtering \n",
        "\n",
        "      *In this technique we try to predict on basis of what user may like based on the ratings that they had given to the items. In simpe words here we try to indentify the neghbouring users on the basis of similarity of active users and then scoring of the items  is calculated on the basis of those neighbour users* \n",
        "   *  Item_based Collaborative Filtering\n",
        "\n",
        "      *In Item based collaborative filtering we try to find similar items based on the items whichs user has liked or interacted with .It suggests an item based on items the user has previously consumed. It looks for the items the user has consumed then it finds other items similar to consumed items and recommends accordingly*\n",
        "\n",
        "\n",
        "   Model based Collaborative Filtering Approach\n",
        "   * Singular value decomposition(SVD)\n",
        "\n",
        "     *It is a popular method in field of Data Science and Machine Learning .It is a classical method from the Linear Algebra concept. It is popular beacuse of its properties and its use in Recomendation System. We can use this in recomending Books, movies etc.*\n",
        "\n",
        "     *SVD is a method from linear algebra that has been generally used as a dimensionality reduction technique in ML problems. It is amtrix Factorisation technique which tries to reduce the number of feature or attributes by reducing the sapce dimension from N dimension to I dimension.SVD is used as a collaborative filtering technique in recomendation technique domain. It consist of a matrix structure where the rows define the users and columns defines the item.*\n",
        "\n",
        "\n",
        "  * Non-Negetive Matrix Factorisation(NMF): \n",
        "  \n",
        "    *Our goal in NMF is to approximate the users-item V matrix by the dot product of two arrays W and H. Dimensions of the arrays are defined by dimensions of V and number of components we set to the algorithm. If V has n rows and m columns and we want to decompose it to k components, then W has n rows, and k columns and H has k rows and m columns.This is actually matrix factorization part of the algorithm. The Non-negative part refers to V, W, and H — all the values have to be equal or greater than zero, i.e., non-negative*\n",
        "   \n",
        "\n",
        "\n",
        "**Content based Filtering :**\n",
        "  \n",
        "   It is type of recomendation system which depends upon the data which we get from the customers , based on the data a user profile is generated"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HIiYB16joaut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/dil150898/Book-Recommendation-System--Capstone-Project"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9GZ7gmTNohCw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### During the last few decades, with the rise of Youtube, Amazon, Netflix, and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.\n",
        "\n",
        "### In a very general way, recommender systems are algorithms aimed at suggesting relevant items to users (items being movies to watch, text to read, products to buy, or anything else depending on industries). Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors. The main objective is to create a book recommendation system for users."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For implimentation of SVD and NMF techniques we require Surprise library"
      ],
      "metadata": {
        "id": "keQ6NdOuk7zQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "OU9S1VwQrXSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For implimentation of SVD and NMF techniques we require Surprise library"
      ],
      "metadata": {
        "id": "2Vl9ovgfq22e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install surprise"
      ],
      "metadata": {
        "id": "gnckZYjJk5q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# for dealing with regular expression techniques\n",
        "import re\n",
        "import requests\n",
        "import random\n",
        "#for NLP related tasks\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "\n",
        "# basic libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#for TF-IDF vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# for finding similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import scipy\n",
        "import math\n",
        "import sklearn\n",
        "#for removing stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "#for SVD model\n",
        "from scipy.sparse.linalg import svds\n",
        "# for plotting graphs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from surprise import Dataset, Reader\n",
        "from surprise import SVD, NMF\n",
        "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "# Import Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset Vaibhav\n",
        "path_book='/content/drive/MyDrive/Almabetter/Capstone Project/Unsupervised Machine Learning/Book Recommendation System/Book Recommendation System/Dil khush Sharma/data_book_recommendation/Books.csv'\n",
        "df_books=pd.read_csv(path_book)\n",
        "\n",
        "path_rating='/content/drive/MyDrive/Almabetter/Capstone Project/Unsupervised Machine Learning/Book Recommendation System/Book Recommendation System/Dil khush Sharma/data_book_recommendation/Ratings.csv'\n",
        "df_ratings=pd.read_csv(path_rating)\n",
        "\n",
        "path_users='/content/drive/MyDrive/Almabetter/Capstone Project/Unsupervised Machine Learning/Book Recommendation System/Book Recommendation System/Dil khush Sharma/data_book_recommendation/Users.csv'\n",
        "df_users=pd.read_csv(path_users)"
      ],
      "metadata": {
        "id": "ZCfo7a1xpEPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df_books.head(3)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings.head(3)"
      ],
      "metadata": {
        "id": "g5dsrvZeqJt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_users.head(3)"
      ],
      "metadata": {
        "id": "7zPzSCD6qRr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "print(f\"Books has {df_books.shape[0]} rows and {df_books.shape[1]} columns \" )\n",
        "print(f\"Rating has {df_ratings.shape[0]} rows and {df_ratings.shape[1]} columns \" )\n",
        "print(f\"Users has {df_users.shape[0]} rows and {df_users.shape[1]} columns \" )"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  books have 271360 rows and 8 columns\n",
        "*  ratings has 1149780 rows and 3 columns\n",
        "*  Users has 278858 rows and 3 columns\n"
      ],
      "metadata": {
        "id": "T0c8qWV6qkve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df_books.info()\n"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings.info()"
      ],
      "metadata": {
        "id": "N8mdOf9u5cMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_users.info()"
      ],
      "metadata": {
        "id": "zWH-4NbD5wLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "# Missing Values/Null Values Count\n",
        "print(\"Duplicate Values in BOOKS\" ,len(df_books[df_books.duplicated()]))\n",
        "print(\"Duplicate Values in RATINGS \",len(df_ratings[df_ratings.duplicated()]))\n",
        "print(\"Duplicate Values in USERS\",len(df_users[df_users.duplicated()]))"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(\"NULL Values in BOOKS\" ,df_books.isnull().sum())\n",
        "print(\"NULL Values in RATINGS \",df_ratings.isnull().sum())\n",
        "print(\"NULL Values in USERS\",df_users.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.displot(\n",
        "    data=df_books.isnull().melt(value_name=\"missing\"),\n",
        "    y=\"variable\",\n",
        "    hue=\"missing\",\n",
        "    multiple=\"fill\",\n",
        "    aspect=1.25\n",
        ")"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the missing values are very less as compared to total number of instances ,therefore we are not able visualie the missing values . The number of missing values are 1,2 and 3 and total insatnces is 271360 so the proportion is 0.000011 hence it is negligible"
      ],
      "metadata": {
        "id": "nqVyadXhrXFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.displot(\n",
        "    data=df_users.isnull().melt(value_name=\"missing\"),\n",
        "    y=\"variable\",\n",
        "    hue=\"missing\",\n",
        "    multiple=\"fill\",\n",
        "    aspect=1.25\n",
        ")"
      ],
      "metadata": {
        "id": "MmegbKgm4y7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* For the users data we have about 0.4 proportion values of the Age column which is missing."
      ],
      "metadata": {
        "id": "RZBCT5e25MXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  There 271360 rows and 8 columns in Books Dataset \n",
        "\n",
        "*  There are  1149780 rows and 3 columns in Rating Dataset\n",
        "\n",
        "*  There are 278858 rows and 3 columns in Users Dataset\n",
        "\n",
        "*  There are no duplicate values in any of the dataset for Books ,Ratings and Users\n",
        "\n",
        "* There are very few (0.0011%) values which are missing for the columns Book_author , Publisher and Image_URL-L"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df_books.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings.columns"
      ],
      "metadata": {
        "id": "NC0LMF2H0agz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_users.columns"
      ],
      "metadata": {
        "id": "rHZ999T509Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df_books.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings.describe()"
      ],
      "metadata": {
        "id": "kNY0ItLZ3G6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_users.describe()"
      ],
      "metadata": {
        "id": "1ED4vZgr3NEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Books are identified by their respective **ISBN**. Moreover, some content-based information is given (**Book-Title, Book-Author, Year-Of-Publication, Publisher**) are obtained from Amazon Web Services. \n",
        "\n",
        "*  URLs linking to cover images are also given,It has basicaly three flovors of images (**Image-URL-S, Image-URL-M, Image-URL-L**), i.e., small, medium, large. These URLs point to the Amazon web site."
      ],
      "metadata": {
        "id": "nzeXYjvn9H22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Users variables\n",
        "   *  The average age of the users of books reader is 34-35 \n",
        "*  Ratings variables\n",
        "   *  The average rating given by the user is 2.8669 out of 10\n",
        "   *  Range of rating is 0-10\n",
        "\n",
        "*  Books variables\n",
        "   *  There are total 102023 unique Authors listed in this dataset\n",
        "   *  Top publisher which has largest number of books listed in this dataset is Harlequin\n",
        "   *  There are 16807 unique publishers listed in this Dataset"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df_books.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings.nunique()"
      ],
      "metadata": {
        "id": "XHwlw_VO6ROs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_users.nunique()"
      ],
      "metadata": {
        "id": "iQSkNCVt6XGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# first we have to merge the datsets \n",
        "df_books_rating=df_books.merge(df_ratings,on=\"ISBN\")\n",
        "df_books_rating.head(3)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  **Checking the percentage of books which have  0 rating**"
      ],
      "metadata": {
        "id": "AQ9lq9RaIYXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'there are {(len(df_books_rating[df_books_rating[\"Book-Rating\"]==0])/len(df_books_rating))*100} of the books which have 0 rating' )"
      ],
      "metadata": {
        "id": "bDANyx_8Fy-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  **Droping some unnecessary columns and data**"
      ],
      "metadata": {
        "id": "zJNCi7ZIInGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_books_rating_copy=df_books_rating.copy()\n",
        "# removing null values\n",
        "df_books_rating_copy.dropna(inplace=True)\n",
        "df_books_rating_copy.reset_index(drop=True,inplace=True)\n",
        "\n",
        "\n",
        "# as the columns ISBN has no use for the analysis also Year-Of-publication\n",
        "# we can also remove the medium and small scale of a image link i.e Image-URL-S and Image-URL-M\n",
        "df_books_rating_copy.drop(columns=[\"ISBN\",\"Year-Of-Publication\",\"Image-URL-S\",\"Image-URL-M\"],axis=1,inplace=True)\n",
        "\n",
        "# we can also drop the book details where the ratings is 0 as it is not a valid rating\n",
        "df_books_rating_copy.drop(index=df_books_rating_copy[df_books_rating_copy[\"Book-Rating\"]==0].index,inplace=True)\n",
        "\n",
        "df_books_rating_copy[\"Book-Title\"]=df_books_rating_copy[\"Book-Title\"].apply(lambda x: re.sub(\"[\\W_]+\",\" \",x).strip())\n",
        "df_books_rating_copy.head()"
      ],
      "metadata": {
        "id": "KDw_roS5991t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Top 20 author with number of books**"
      ],
      "metadata": {
        "id": "oIEKESxjiEhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(y=\"Book-Author\",palette = 'Paired', data=df_books,order=df_books['Book-Author'].value_counts().index[0:20])\n",
        "plt.title(\"Top 20 author with number of books\")"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  To get the top 20 Author with number of Books\n"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Based on this dataset Agatha Christie released maximums books .Followed by William Shakespeare and Stephen King are 2nd and 3rd most Authors who have relased maximum books."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# plotting the rating column distribusion\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.countplot(x=\"Book-Rating\", data=df_ratings)\n",
        "plt.title(\"Ratings\")"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To study the distribustion of Rating"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Most of the books have 0 rating . As might be most of the books were not read , or not recorded its ratings . So during the time of dataset preparation they might have explicitly filled with zeros\n",
        "\n",
        "\n",
        "* If we ignore this 0 ratings then 8 is the most common rating given by users out of 10"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Top 10 Books with highest nuumber of ratings**"
      ],
      "metadata": {
        "id": "wsXpJhr2EHej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "valid_rating=df_ratings[df_ratings['Book-Rating'] != 0]\n",
        "top10_ratings=valid_rating.groupby('ISBN')['Book-Rating'].count().sort_values(ascending=False).head(10)\n",
        "top10_ratings"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Users Age distribution**"
      ],
      "metadata": {
        "id": "D6_Wx7Z0IRQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Checking data distribution from distplot\n",
        "sns.distplot(df_users.Age)\n",
        "plt.title('Age Distribution Plot')"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To study the distriution of Age"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Age is postively skewed it may contain outliers also we have some age as 0 , which might be explicity filled for the users who hadn't reported their age"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Checking Outliers for the Users Age column**"
      ],
      "metadata": {
        "id": "r2SUthhuJt1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x='Age',data=df_users)"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To check the outliers in the age column"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We can notice that there are some outliers for age column"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(y=\"Book-Author\",palette = 'Paired', data=df_books_rating_copy,order=df_books_rating_copy['Book-Author'].value_counts().index[0:20])\n",
        "plt.title(\"Top 20 author with maximum number of rating\")"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To study the Authors who got highest number of votes or ratings"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As per this dataset Stephen King is the Author who got maximum number of ratings by the users"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Top 10 books which got highest numbers of rating**"
      ],
      "metadata": {
        "id": "_kH_Roe7DdvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "df_books_rating_copy.groupby(['Book-Title'])['Book-Rating'].count().sort_values(ascending=False).head(10).plot(kind='bar')"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To study the highest rated Books"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Top-10 most rated books were essentially novels. Books like The Lovely Bone and Wild Animus were very famous"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Top 10 publishers with maximum number of ratings**"
      ],
      "metadata": {
        "id": "mLdkTkbIDwiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_books.columns"
      ],
      "metadata": {
        "id": "WPc9OeFrOibd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(y='Publisher',palette = 'Paired', data=df_books,order=df_books['Publisher'].value_counts().index[0:10])\n",
        "plt.title(\"Top 10 'Publisher' with maximum number of rating\")"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To study the Publishers who have got most ratings"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Most of the books were  pulblised by Hariequin, Silhouette and Pocket"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# filling null values of the age column of users data\n",
        "# as age contains outliers so we can use median\n",
        "df_users[\"Age\"].fillna(df_users.Age.median(),inplace=True)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the unique values of year of publication\n",
        "df_books['Year-Of-Publication'].unique()"
      ],
      "metadata": {
        "id": "p-uwvNFuWXj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There are values such as 'DK Publishing Inc' and 'Gallimard' which are in text form \n",
        "\n",
        "* There are values such as 0 for the year-of-publication column\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RRjkAiOMYPkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the data where the 'Year-Of-Publication' is 'DK Publishing Inc'\n",
        "df_books.loc[df_books['Year-Of-Publication'] == 'DK Publishing Inc',:]"
      ],
      "metadata": {
        "id": "99tOKKeIYzUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We can notice that the Book-Author ,Year-of-Publication , Book-Author and Publisher columns are exchanged with each others and publication column contain image links\n",
        "\n",
        "* we need to find the Book-Author on our own for the book DK Readers: Creating the X-Men, How It All Beg.. and DK Readers: Creating the X-Men, How Comic Book.."
      ],
      "metadata": {
        "id": "4gcJ5Cc1ZQbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fixing the wrongly inputed values \n",
        "#ISBN '0789466953'\n",
        "df_books.loc[df_books.ISBN == '0789466953','Year-Of-Publication'] = 2000\n",
        "df_books.loc[df_books.ISBN == '0789466953','Book-Author'] = \"James Buckley\" # this we gathered from the google \n",
        "df_books.loc[df_books.ISBN == '0789466953','Publisher'] = \"DK Publishing Inc\"\n",
        "df_books.loc[df_books.ISBN == '0789466953','Book-Title'] = \"DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)\"\n",
        "\n",
        "#ISBN '078946697X'\n",
        "df_books.loc[df_books.ISBN == '078946697X','Year-Of-Publication'] = 2000\n",
        "df_books.loc[df_books.ISBN == '078946697X','Book-Author'] = \"Michael Teitelbaum\" # this we gathered from the google\n",
        "df_books.loc[df_books.ISBN == '078946697X','Publisher'] = \"DK Publishing Inc\"\n",
        "df_books.loc[df_books.ISBN == '078946697X','Book-Title'] = \"DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)\"\n"
      ],
      "metadata": {
        "id": "q9eXWRNpZeuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for the Gallimard\n",
        "df_books.loc[df_books['Year-Of-Publication'] == 'Gallimard',:]"
      ],
      "metadata": {
        "id": "GH32OAsjbBLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here also we can see that Book-Author, year-of-publication and publishers values are interchnaged and publishers actual name is missing"
      ],
      "metadata": {
        "id": "QEpyxZysbVWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_books.loc[df_books.ISBN == '2070426769','Year-Of-Publication'] = 2003\n",
        "df_books.loc[df_books.ISBN == '2070426769','Book-Author'] = \"Jean-Marie Gustave Le ClÃ?Â©zio\"\n",
        "df_books.loc[df_books.ISBN == '2070426769','Publisher'] = \"Gallimard\"\n",
        "df_books.loc[df_books.ISBN == '2070426769','Book-Title'] = \"Peuple du ciel, suivi de 'Les Bergers\""
      ],
      "metadata": {
        "id": "XQmxXEkmbj5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rechecking the correction made\n",
        "df_books['Year-Of-Publication'].unique()"
      ],
      "metadata": {
        "id": "4WNpS9azb3kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_books['Year-Of-Publication'] = df_books['Year-Of-Publication'].astype(int)\n",
        "# Replacing invalid values such as year greateer than 2022 and year having 0 with the NaN\n",
        "# so that we can fill those null values with proper measure of centreal tendency\n",
        "\n",
        "df_books.loc[(df_books['Year-Of-Publication'] > 2022) | (df_books['Year-Of-Publication'] == 0),'Year-Of-Publication'] = np.NAN\n",
        "\n",
        "# filling the null values with median values as there are outliers in year-of-publication column\n",
        "df_books['Year-Of-Publication'].fillna(round(df_books['Year-Of-Publication'].median()),inplace=True)"
      ],
      "metadata": {
        "id": "28Hb_pI0cCfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling null values for the column Book-Author and Publisher\n",
        "# as we have only very few null values  1 and 2 only so we acn fill those values with other \n",
        "df_books[\"Book-Author\"].fillna(\"other\", inplace = True)  \n",
        "df_books[\"Publisher\"].fillna(\"other\", inplace = True)  "
      ],
      "metadata": {
        "id": "P68iar-kc_lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Filling the values with median when the column contain outilers "
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "Q3,Q1 = np.percentile(df_users['Age'],[75,25])\n",
        "#Calculating Inter Quartile Range\n",
        "IQR = Q3-Q1\n",
        "#Fixing Boundaries for outliers\n",
        "max = Q3+(1.5*IQR)\n",
        "min = Q1-(1.5*IQR)\n",
        "df_users[\"Age\"] = np.where(df_users[\"Age\"] > max, max, df_users['Age'])\n",
        "df_users[\"Age\"] = np.where(df_users[\"Age\"] < min, min, df_users['Age'])"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chceking the outliers again\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "sns.boxplot(x='Age',data=df_users)"
      ],
      "metadata": {
        "id": "RKpU11S3faec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We can notice that the Outliers has been handeled smoothly and now we dont have any outliers"
      ],
      "metadata": {
        "id": "Yt2kDmyQfgT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We used IQR method to fill the right side otliers with maximum value calculated from IQR and Left side outliers with the minimum value calculated from IQR"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Popularity Based Approach**\n",
        "\n",
        "* The main idea behind Popularity Based Approach is to recomend the books which are popular , the popularity can be calculated on the basis of ratings "
      ],
      "metadata": {
        "id": "_Dvi62FHLnOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def popularity_approach(df,number_of_top_book=50):\n",
        "    # first we have groupy with Book-Ttle and Book-rating as we wou recomend popularity on the these columns  \n",
        "    rating_counts=df.groupby(\"Book-Title\").count()[\"Book-Rating\"].reset_index()\n",
        "    # counting the number of ratings that particular book-title has got\n",
        "    rating_counts.rename(columns={\"Book-Rating\":\"num_of_ratings\"},inplace=True)\n",
        "    \n",
        "    # calculating average rating\n",
        "    rating_avg=df.groupby(\"Book-Title\")[\"Book-Rating\"].mean().reset_index()\n",
        "    rating_avg.rename(columns={\"Book-Rating\":\"average_rating\"},inplace=True)\n",
        "    \n",
        "    df_popular_books=rating_counts.merge(rating_avg,on=\"Book-Title\")\n",
        "\n",
        "    # average rating can be misguiding as they may be baised to number of ratings\n",
        "    # so taking account of number of ratings for particular book-title\n",
        "    # therefore  creating a function for calculating meaningfull average rating\n",
        "    mean_avg_rating=df_popular_books[\"average_rating\"].mean()\n",
        "    total_ratings=df_popular_books[\"num_of_ratings\"].quantile(0.90)\n",
        "    def weighted_rate(df):\n",
        "        number_of_rating_vector=df[\"num_of_ratings\"]\n",
        "        average_rating_vector=df[\"average_rating\"]\n",
        "        \n",
        "        return ((number_of_rating_vector*average_rating_vector) + (total_ratings*mean_avg_rating)) / (number_of_rating_vector+total_ratings)\n",
        "    \n",
        "    \n",
        "    # checking only for books which got more than \n",
        "    df_popular_books=df_popular_books[df_popular_books[\"num_of_ratings\"] >=100]\n",
        "    # calculating popularity of books using weighted_rate\n",
        "    df_popular_books[\"popularity\"]=df_popular_books.apply(weighted_rate,axis=1)\n",
        "    # sorting the books by its popularity in decending order\n",
        "    df_popular_books=df_popular_books.sort_values(by=\"popularity\",ascending=False)\n",
        "    # returning the top n books \n",
        "    return df_popular_books[[\"Book-Title\",\"num_of_ratings\",\"average_rating\",\"popularity\"]].reset_index(drop=True).head(number_of_top_book)"
      ],
      "metadata": {
        "id": "IG6oxvBiLltx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 20 popular books\n",
        "top_20=pd.DataFrame(popularity_approach(df_books_rating_copy,20))\n",
        "top_20"
      ],
      "metadata": {
        "id": "MxCt33qfW8b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Collaborative Filtering Approaches**\n",
        "\n",
        "In Collaborative Filtering we make predictions of the taste or the intrests of the user based based on the other similar users behaviour (which is called collaborative) .The simple understanding is that if a person P1 have similar opinion with person P2 , then if person P1 is reading Harry Potter books then person P2 may also read Harry Potter books\n",
        "\n",
        "Collaborative Filtering has mainly two implimentaion strategies\n",
        "*   Model Based\n",
        "*   Memory Based\n",
        "\n",
        "we will use following approaches\n",
        "*  User_based Collaborative Filtering and \n",
        "*  Item_based Collaborative Filtering\n",
        "\n",
        "* Content Based Filtering\n",
        "\n",
        "\n",
        "*  Model based Collaborative Filtering Approach\n",
        "  * Singular value decomposition(SVD)\n",
        "  * Non-Negetive Matrix Factorisation(NMF)"
      ],
      "metadata": {
        "id": "V9tX8VhwZmfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **User Based Collaborative Filtering**\n",
        "\n",
        "*  In this technique we try to predict on basis of what user may like based on the ratings that they had given to the items. In simpe words here we try to indentify the neghbouring users on the basis of similarity of active users and then scoring of the items  is calculated on the basis of those neighbour users"
      ],
      "metadata": {
        "id": "pR3HE03Xgv0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop users who have given less number of votings \n",
        "# we will drop the users where the number of votes are less than 100\n",
        "new_df=df_books_rating_copy[df_books_rating_copy['User-ID'].map(df_books_rating_copy['User-ID'].value_counts()) > 100] \n",
        "\n",
        "# creating a pivot tables consisting user realted information\n",
        "users_info=new_df.pivot_table(index=[\"User-ID\"],columns=[\"Book-Title\"],values=\"Book-Rating\")\n",
        "users_info.fillna(0,inplace=True)\n"
      ],
      "metadata": {
        "id": "_DSi-vj_bbx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_info.head(3)"
      ],
      "metadata": {
        "id": "HmJT7y0Iimvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choice_of_users(id):\n",
        "    \n",
        "    user_favourite=new_df[new_df[\"User-ID\"]==id].sort_values([\"Book-Rating\"],ascending=False)[0:10]\n",
        "    return user_favourite\n",
        "\n",
        "def user_based_collaborative(new_df,user_id):\n",
        "    if user_id not in new_df[\"User-ID\"].values:\n",
        "        print(\"USER NOT FOUND\")\n",
        "        \n",
        "        \n",
        "    else:\n",
        "        user_index=np.where(users_info.index==user_id)[0][0]\n",
        "        similar=cosine_similarity(users_info)\n",
        "        similar_users_list=list(enumerate(similar[user_index]))\n",
        "        similar_users_list = sorted(similar_users_list,key = lambda x:x[1],reverse=True)[0:10]\n",
        "    \n",
        "        record_of_users=[]\n",
        "    \n",
        "        for ind in similar_users_list:\n",
        "                data=df_books_rating_copy[df_books_rating_copy[\"User-ID\"]==users_info.index[ind[0]]]\n",
        "                record_of_users.extend(list(data.drop_duplicates(\"User-ID\")[\"User-ID\"].values))\n",
        "        \n",
        "    return record_of_users\n",
        "\n",
        "def common(df,users_list,user_id):\n",
        "    temp1=new_df[df[\"User-ID\"]==user_id]\n",
        "    suggested_books=[]\n",
        "    users_list=list(users_list)\n",
        "    for id in users_list:\n",
        "        temp2=df[(df[\"User-ID\"]==id)]\n",
        "        all_books=temp2.loc[~temp2[\"Book-Title\"].isin(temp1[\"Book-Title\"]),:]\n",
        "        all_books=all_books.sort_values([\"Book-Rating\"],ascending=False)[0:10]\n",
        "        suggested_books.extend(all_books[\"Book-Title\"].values)\n",
        "        \n",
        "    return suggested_books[0:10]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m_aAVve9iwCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taking any random user_id\n",
        "random_user_id=random.choice(new_df[\"User-ID\"].values)\n",
        "# showing users choice based on history\n",
        "user_choice=pd.DataFrame(choice_of_users(random_user_id))\n",
        "# subseting users favourite from users choice\n",
        "user_favorite=choice_of_users(random_user_id)\n",
        "n=len(user_choice[\"Book-Title\"].values)\n",
        "print(f\"USER: {random_user_id} \")"
      ],
      "metadata": {
        "id": "pBuNdD7Kz6Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_favorite"
      ],
      "metadata": {
        "id": "YKT8FTXL7MFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting user based data for particular random user id\n",
        "user_based=user_based_collaborative(new_df,random_user_id)\n",
        "# getting recomended books for that particular random user id\n",
        "book_suggesions_user=common(new_df,user_based,random_user_id)\n",
        "# ceating a dataframe to store the results\n",
        "book_suggesions_user=pd.DataFrame(book_suggesions_user,columns=[\"Book-Title\"])\n",
        "book_suggesions_user"
      ],
      "metadata": {
        "id": "t-Ad5Iwj8omW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Item Based Collaborative Filtering**\n",
        "\n",
        "*  In Item based collaborative filtering we try to find similar items based on the items whichs user has liked or interacted with .It suggests an item based on items the user has previously consumed. It looks for the items the user has consumed then it finds other items similar to consumed items and recommends accordingly"
      ],
      "metadata": {
        "id": "Y5JVf8V6-EY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def item_based_approach(data,querry_bookTitle,number_of_suggesions):\n",
        "    querry_bookTitle=str(querry_bookTitle)\n",
        "    \n",
        "    if querry_bookTitle in data[\"Book-Title\"].values:\n",
        "        count_rating=pd.DataFrame(data[\"Book-Title\"].value_counts())\n",
        "        # seperating rare books\n",
        "        rare=count_rating[count_rating[\"Book-Title\"]<=100].index\n",
        "        # defining common books \n",
        "        # as those books which are not rare are common books\n",
        "        common_b=data[~data[\"Book-Title\"].isin(rare)]\n",
        "        \n",
        "        # If the qerry book title is very rare then we would suggest the most common books\n",
        "        if querry_bookTitle in rare:\n",
        "            # storing most common books \n",
        "            ran5=pd.Series(common_b[\"Book-Title\"].unique()).sample(5).values\n",
        "            print(\"No hard recomendation for this book can be suggested\")\n",
        "            print(\"but you can try with most common books \")\n",
        "            # suggesting randomly 5 books from set of common books\n",
        "            print(f\"1st {ran5[0]}\")\n",
        "            print(f\"2nd {ran5[1]}\")\n",
        "            print(f\"3rd {ran5[2]}\")\n",
        "            print(f\"4th {ran5[3]}\")\n",
        "            print(f\"5th {ran5[4]}\")\n",
        "        else:\n",
        "            common_b_pivot=common_b.pivot_table(index=[\"User-ID\"],columns=[\"Book-Title\"],values=\"Book-Rating\")\n",
        "            # defining book-title as t\n",
        "            t=common_b_pivot[querry_bookTitle]\n",
        "            # making suggesions based on the correlation\n",
        "            suggesion_df=pd.DataFrame(common_b_pivot.corrwith(t).sort_values(ascending=False)).reset_index(drop=False)\n",
        "            \n",
        "            if querry_bookTitle in [ele for ele in suggesion_df[\"Book-Title\"]]:\n",
        "                suggesion_df=suggesion_df.drop(suggesion_df[suggesion_df[\"Book-Title\"]==querry_bookTitle].index[0])\n",
        "                \n",
        "            less_rating=[]\n",
        "            for ele in suggesion_df[\"Book-Title\"]:\n",
        "                if data[data[\"Book-Title\"]==ele][\"Book-Rating\"].mean() < 5:\n",
        "                    less_rating.append(ele)\n",
        "            if suggesion_df.shape[0] - len(less_rating) > 5:\n",
        "                suggesion_df=suggesion_df[~suggesion_df[\"Book-Title\"].isin(less_rating)]\n",
        "                \n",
        "            suggesion_df=suggesion_df[0:number_of_suggesions]\n",
        "            suggesion_df.columns=[\"Book-Title\",\"Correlation\"]\n",
        "\n",
        "            return suggesion_df\n",
        "            \n",
        "    else:\n",
        "        print(\"No Results Found  !!!\")"
      ],
      "metadata": {
        "id": "f1-nc-Sx-M4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting top 10 suggesions from item-based approach\n",
        "item_based_approach(df_books_rating_copy,\"The Da Vinci Code\",10)"
      ],
      "metadata": {
        "id": "PajxtNes_nPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# when the book title is not present\n",
        "item_based_approach(df_books_rating_copy,\"machine learning\",10)"
      ],
      "metadata": {
        "id": "s1rafgfPFUmJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}